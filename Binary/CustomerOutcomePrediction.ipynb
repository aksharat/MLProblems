{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMsnuQ6hddxFN6l5xa6UHpY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aksharat/MLProblems/blob/main/Binary/CustomerOutcomePrediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### Instructions:\n",
        "\n",
        "- Fill in the methods of the DataModeler class to produce the same printed results\n",
        "  as in the comments labeled `Expected Output` in the second half of the file.\n",
        "- The DataModeler should predict the 'outcome' from the columns 'amount' and 'transaction date.'\n",
        "  Your model should ignore the 'customer_id' column.\n",
        "- For the modeling methods `fit`, `predict` and `model_summary` you can use any appropriate method.\n",
        "  Try to get 100% accuracy on both training and test, as indicated in the output.\n",
        "- Please feel free to import any popular libraries of choice for your solution!\n",
        "- Your solution will be judged on both correctness and code quality.\n",
        "- Good luck, and have fun!\n",
        "\n"
      ],
      "metadata": {
        "id": "GC3RA8b1p2l8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "qHiww4w_pq5b"
      },
      "outputs": [],
      "source": [
        "# required in python 3.7 or so to consider annotations as strings\n",
        "from __future__ import annotations  # From 3.11, it isn't required as it is considered by default"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#import the standard libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from matplotlib import dates as mdates\n",
        "from sklearn.impute import SimpleImputer\n",
        "# import the library\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "import pickle"
      ],
      "metadata": {
        "id": "Epfj2NQrqv02"
      },
      "execution_count": 126,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DataModeler:\n",
        "  def __init__(self, sample_df: pd.DataFrame):\n",
        "        '''\n",
        "        Initialize the DataModeler as necessary.\n",
        "        '''\n",
        "        # ** Your code here **\n",
        "        # keep a copy of the sample_df i.e the training data. This would be used in case of no external data available\n",
        "        self.train_df = sample_df.copy()\n",
        "        # self.train_df.reset_index(drop=True, inplace=True)\n",
        "        # Store the labels and the customer_ids for retrival\n",
        "        self.labels = sample_df['outcome']\n",
        "        self.ids = sample_df['customer_id']\n",
        "        # self.train_df.drop(columns=['outcome','customer_id'],inplace=True)\n",
        "        # Set the model placeholder\n",
        "        self.model = None\n",
        "  def prepare_data(self, oos_df: pd.DataFrame = None) -> pd.DataFrame:\n",
        "      '''\n",
        "      Prepare a dataframe so it contains only the columns to model and having suitable types.\n",
        "      If the argument is None, work on the training data passed in the constructor.\n",
        "      '''\n",
        "      # ** Your code here **\n",
        "      # Set a flag to see to check the existance of the oos_df\n",
        "      flag=0\n",
        "      if oos_df is None:\n",
        "        oos_df = self.train_df\n",
        "        flag=1\n",
        "\n",
        "      # oos_df = oos_df.loc[:,[\"amount\",\"transaction_date\"]]\n",
        "      # Convert the object datatype to datetime, errors are set to NaT\n",
        "      oos_df[\"transaction_date\"] = pd.to_datetime(oos_df[\"transaction_date\"],errors='coerce')\n",
        "      # Convert the datetime dtype to numeric, i.e float, errors are set to np.nan or junk value\n",
        "      oos_df[\"transaction_date\"] = pd.to_numeric(oos_df[\"transaction_date\"],errors='coerce')\n",
        "      # Replace non-positive values (due to error coerce through the pandas functions of datetime and numeric) with np.nan\n",
        "      oos_df.loc[oos_df[\"transaction_date\"] <= 0, \"transaction_date\"] = np.nan\n",
        "      if flag==1:\n",
        "        # use the data from the constructor\n",
        "        self.train_df = oos_df.drop(columns=['customer_id','outcome'])\n",
        "      else:\n",
        "        # external data is available\n",
        "        if 'outcome' in oos_df.columns:\n",
        "          # Column exists,set the outcome labels\n",
        "          self.labels = oos_df['outcome']\n",
        "        # set the ids based on customer id\n",
        "        self.ids = oos_df['customer_id']\n",
        "        # return just the necessary features\n",
        "        return oos_df.loc[:,[\"amount\",\"transaction_date\"]]\n",
        "\n",
        "  def impute_missing(self, oos_df: pd.DataFrame = None) -> pd.DataFrame:\n",
        "      '''\n",
        "      Fill any missing values with the appropriate mean (average) value.\n",
        "      If the argument is None, work on the training data passed in the constructor.\n",
        "      '''\n",
        "      # Set a flag to see to check the existance of the oos_df\n",
        "      flag=0\n",
        "      if oos_df is None:\n",
        "        oos_df = self.train_df\n",
        "        flag=1\n",
        "      # Impute missing values with the mean\n",
        "      imp_mean = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
        "      imputed_df = pd.DataFrame(imp_mean.fit_transform(oos_df), columns=oos_df.columns)\n",
        "      if flag==1:\n",
        "        # add in the customer ids\n",
        "        self.train_df = pd.concat([self.ids,imputed_df],axis=1)\n",
        "      else:\n",
        "        # return the concatenation of the ids for reference and the imputed df\n",
        "        return pd.concat([self.ids,imputed_df],axis=1)\n",
        "\n",
        "\n",
        "  def fit(self) -> None:\n",
        "      '''\n",
        "      Fit the model of your choice on the training data paased in the constructor, assuming it has\n",
        "      been prepared by the functions prepare_data and impute_missing\n",
        "      '''\n",
        "      # ** Your code here **\n",
        "      # self.model = DecisionTreeClassifier(min_samples_split=10,max_depth=3)\n",
        "      # self.model.fit(self.train_df.drop(columns=['customer_id']), self.labels)\n",
        "      self.model = GradientBoostingClassifier()\n",
        "      self.model.fit(self.train_df.drop(columns=['customer_id']), self.labels)\n",
        "  def model_summary(self) -> str:\n",
        "      '''\n",
        "      Create a short summary of the model you have fit.\n",
        "      '''\n",
        "      # ** Your code here **\n",
        "      if self.model is None:\n",
        "        return \"Model has not been trained yet.\"\n",
        "\n",
        "      if isinstance(self.model, DecisionTreeClassifier):\n",
        "        # to get the feature importance params\n",
        "        feature_importance = self.model.feature_importances_\n",
        "        params = self.model.get_params()\n",
        "\n",
        "        summary = f\"Decision Tree Model Summary:\\n\"\n",
        "        summary += f\"Feature Importance: {feature_importance}\\n\"\n",
        "        summary += f\"Model Parameters: {params}\\n\"\n",
        "        return summary\n",
        "\n",
        "      elif isinstance(self.model, GradientBoostingClassifier):\n",
        "          # to get the feature importance params\n",
        "          feature_importance = self.model.feature_importances_\n",
        "          params = self.model.get_params()\n",
        "\n",
        "          summary = f\"Gradient Boosting Model Summary:\\n\"\n",
        "          summary += f\"Feature Importance: {feature_importance}\\n\"\n",
        "          summary += f\"Model Parameters: {params}\\n\"\n",
        "          return summary\n",
        "\n",
        "      return \"Model summary not available for this model type.\"\n",
        "\n",
        "  def predict(self, oos_df: pd.DataFrame = None) -> pd.Series[bool]:\n",
        "      '''\n",
        "      Make a set of predictions with your model. Assume the data has been prepared by the\n",
        "      functions prepare_data and impute_missing.\n",
        "      If the argument is None, work on the training data passed in the constructor.\n",
        "      '''\n",
        "      # ** Your code here **\n",
        "      if oos_df is None:\n",
        "        oos_df = self.train_df\n",
        "      return self.model.predict(oos_df.drop(columns=['customer_id']))\n",
        "\n",
        "  def save(self, path: str) -> None:\n",
        "      '''\n",
        "      Save the DataModeler so it can be re-used.\n",
        "      '''\n",
        "      # ** Your code here **\n",
        "      with open(path, \"wb\") as f:\n",
        "        pickle.dump(self, f)\n",
        "\n",
        "  @staticmethod\n",
        "  def load(path: str) -> DataModeler:\n",
        "      '''\n",
        "      Reload the DataModeler from the saved state so it can be re-used.\n",
        "      '''\n",
        "      # ** Your code here **\n",
        "      with open(path, \"rb\") as f:\n",
        "          modeler = pickle.load(f)\n",
        "\n",
        "      return modeler\n"
      ],
      "metadata": {
        "id": "vVsGnBDNwAHW"
      },
      "execution_count": 236,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "################################################################################"
      ],
      "metadata": {
        "id": "LkM4TUv4w11g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transact_train_sample = pd.DataFrame(\n",
        "    {\n",
        "        \"customer_id\": [11, 12, 13, 14, 15, 16, 17, 18, 19, 20],\n",
        "        \"amount\": [1, 3, 12, 6, 0.5, 0.2, np.nan, 5, np.nan, 3],\n",
        "        \"transaction_date\": [\n",
        "            '2022-01-01',\n",
        "            '2022-08-01',\n",
        "            None,\n",
        "            '2022-12-01',\n",
        "            '2022-02-01',\n",
        "            None,\n",
        "            '2022-02-01',\n",
        "            '2022-01-01',\n",
        "            '2022-11-01',\n",
        "            '2022-01-01'\n",
        "        ],\n",
        "        \"outcome\" : [False, True, True, True, False, False, True, True, True, False]\n",
        "    }\n",
        ")\n"
      ],
      "metadata": {
        "id": "GKvKWGbiw2hf"
      },
      "execution_count": 237,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Training sample:\\n{transact_train_sample}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0jQ2XuwCxmkU",
        "outputId": "f148e0dd-d9d1-4910-faf1-5ed9b7741c5b"
      },
      "execution_count": 238,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training sample:\n",
            "   customer_id  amount transaction_date  outcome\n",
            "0           11     1.0       2022-01-01    False\n",
            "1           12     3.0       2022-08-01     True\n",
            "2           13    12.0             None     True\n",
            "3           14     6.0       2022-12-01     True\n",
            "4           15     0.5       2022-02-01    False\n",
            "5           16     0.2             None    False\n",
            "6           17     NaN       2022-02-01     True\n",
            "7           18     5.0       2022-01-01     True\n",
            "8           19     NaN       2022-11-01     True\n",
            "9           20     3.0       2022-01-01    False\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Expected Output: <br>\n",
        "Training sample:\n",
        "\n",
        "| customer_id | amount | transaction_date | outcome |\n",
        "|-------------|--------|------------------|---------|\n",
        "| 11          | 1.0    | 2022-01-01       | False   |\n",
        "| 12          | 3.0    | 2022-08-01       | True    |\n",
        "| 13          | 12.0   | None             | True    |\n",
        "| 14          | 6.0    | 2022-12-01       | True    |\n",
        "| 15          | 0.5    | 2022-02-01       | False   |\n",
        "| 16          | 0.2    | None             | False   |\n",
        "| 17          | NaN    | 2022-02-01       | True    |\n",
        "| 18          | 5.0    | 2022-01-01       | True    |\n",
        "| 19          | NaN    | 2022-11-01       | True    |\n",
        "| 20          | 3.0    | 2022-01-01       | False   |\n",
        "\n"
      ],
      "metadata": {
        "id": "AkZTYrnRw9V2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Current dtypes:\\n{transact_train_sample.dtypes}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5stRPDHTw969",
        "outputId": "5d557a98-44b8-4473-82fa-2feffe303a6f"
      },
      "execution_count": 239,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Current dtypes:\n",
            "customer_id           int64\n",
            "amount              float64\n",
            "transaction_date     object\n",
            "outcome                bool\n",
            "dtype: object\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Expected Output:<br>\n",
        "Current dtypes:\n",
        "\n",
        "| Column Name        | Data Type |\n",
        "|--------------------|-----------|\n",
        "| customer_id        | int64     |\n",
        "| amount             | float64   |\n",
        "| transaction_date   | object    |\n",
        "| outcome            | bool      |\n"
      ],
      "metadata": {
        "id": "Kx1XskvrxopU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transactions_modeler = DataModeler(transact_train_sample)\n",
        "\n",
        "transactions_modeler.prepare_data()"
      ],
      "metadata": {
        "id": "c7FCZiXBxwUP"
      },
      "execution_count": 240,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Changed columns to:\\n{transactions_modeler.train_df.dtypes}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "szb2LYp_x0pY",
        "outputId": "b8e9c1da-0370-458f-8e7b-bda2d802b3d4"
      },
      "execution_count": 241,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Changed columns to:\n",
            "amount              float64\n",
            "transaction_date    float64\n",
            "dtype: object\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Expected Output:<br>\n",
        "Changed columns to:\n",
        "\n",
        "| Column Name        | Data Type |\n",
        "|--------------------|-----------|\n",
        "| amount             | float64   |\n",
        "| transaction_date   | float64   |"
      ],
      "metadata": {
        "id": "7d176yBCx3uv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transactions_modeler.impute_missing()"
      ],
      "metadata": {
        "id": "9WnRxFgxyD6v"
      },
      "execution_count": 242,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Imputed missing as mean:\\n{transactions_modeler.train_df}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e1iEZgmfyHMq",
        "outputId": "395e36ee-a20c-4eea-dfa5-a05f40702be3"
      },
      "execution_count": 243,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Imputed missing as mean:\n",
            "   customer_id   amount  transaction_date\n",
            "0           11   1.0000      1.640995e+18\n",
            "1           12   3.0000      1.659312e+18\n",
            "2           13  12.0000      1.650845e+18\n",
            "3           14   6.0000      1.669853e+18\n",
            "4           15   0.5000      1.643674e+18\n",
            "5           16   0.2000      1.650845e+18\n",
            "6           17   3.8375      1.643674e+18\n",
            "7           18   5.0000      1.640995e+18\n",
            "8           19   3.8375      1.667261e+18\n",
            "9           20   3.0000      1.640995e+18\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Expected Output:<br>\n",
        "Imputed missing as mean:\n",
        "\n",
        "| customer_id | amount | transaction_date |\n",
        "|-------------|--------|------------------|\n",
        "| 11          | 1.0000 | 1.640995e+18     |\n",
        "| 12          | 3.0000 | 1.659312e+18     |\n",
        "| 13          | 12.0000 | 1.650845e+18    |\n",
        "| 14          | 6.0000 | 1.669853e+18     |\n",
        "| 15          | 0.5000 | 1.643674e+18     |\n",
        "| 16          | 0.2000 | 1.650845e+18     |\n",
        "| 17          | 3.8375 | 1.643674e+18     |\n",
        "| 18          | 5.0000 | 1.640995e+18     |\n",
        "| 19          | 3.8375 | 1.667261e+18     |\n",
        "| 20          | 3.0000 | 1.640995e+18     |\n"
      ],
      "metadata": {
        "id": "RMsyJfd7y46m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Fitting  model\")\n",
        "transactions_modeler.fit()\n",
        "\n",
        "print(f\"Fit model:\\n{transactions_modeler.model_summary()}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9L4PdEO_yIVs",
        "outputId": "397020b4-ead8-41c7-9157-ea53d973e0fd"
      },
      "execution_count": 244,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting  model\n",
            "Fit model:\n",
            "Gradient Boosting Model Summary:\n",
            "Feature Importance: [0.66666667 0.33333333]\n",
            "Model Parameters: {'ccp_alpha': 0.0, 'criterion': 'friedman_mse', 'init': None, 'learning_rate': 0.1, 'loss': 'log_loss', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_iter_no_change': None, 'random_state': None, 'subsample': 1.0, 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "`Expected Output` <br>\n",
        "Fitting  model <br>\n",
        "Fit model:<br>\n",
        " <<< ANY SHORT SUMMARY OF THE MODEL YOU CHOSE >>>"
      ],
      "metadata": {
        "id": "NQS-NtGwy9YR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "in_sample_predictions = transactions_modeler.predict()\n",
        "print(f\"Predicted on training sample: {in_sample_predictions}\\n\")\n",
        "print(f'Accuracy = {sum(in_sample_predictions ==  [False, True, True, True, False, False, True, True, True, False])/.1}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dRHZpU24zIYM",
        "outputId": "622daf72-1ac5-471e-d5c5-c1f3c062767b"
      },
      "execution_count": 245,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted on training sample: [False  True  True  True False False  True  True  True False]\n",
            "\n",
            "Accuracy = 100.0%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "`Expected Output` <br>\n",
        "Predicting on training sample:<br>\n",
        " [False  True  True  True False False True  True  True False]<br>\n",
        "Accuracy = 100.0%"
      ],
      "metadata": {
        "id": "a9aRYBVAzL6_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transactions_modeler.save(\"transact_modeler\")\n",
        "loaded_modeler = DataModeler.load(\"transact_modeler\")\n",
        "\n",
        "print(f\"Loaded DataModeler sample df:\\n{loaded_modeler.model_summary()}\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JkLtX2v8zRmI",
        "outputId": "3883c9a7-cd84-414d-b316-02cf4e9dceb6"
      },
      "execution_count": 246,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded DataModeler sample df:\n",
            "Gradient Boosting Model Summary:\n",
            "Feature Importance: [0.66666667 0.33333333]\n",
            "Model Parameters: {'ccp_alpha': 0.0, 'criterion': 'friedman_mse', 'init': None, 'learning_rate': 0.1, 'loss': 'log_loss', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_iter_no_change': None, 'random_state': None, 'subsample': 1.0, 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "`Expected Output`<br>\n",
        "Loaded DataModeler sample df:<br>\n",
        "<<< THE SUMMARY OF THE MODEL YOU CHOSE >>>"
      ],
      "metadata": {
        "id": "lMUVrBBQzYfh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transact_test_sample = pd.DataFrame(\n",
        "    {\n",
        "        \"customer_id\": [21, 22, 23, 24, 25],\n",
        "        \"amount\": [0.5, np.nan, 8, 3, 2],\n",
        "        \"transaction_date\": [\n",
        "            '2022-02-01',\n",
        "            '2022-11-01',\n",
        "            '2022-06-01',\n",
        "            None,\n",
        "            '2022-02-01'\n",
        "        ]\n",
        "    }\n",
        ")"
      ],
      "metadata": {
        "id": "OVItzFHtzfwU"
      },
      "execution_count": 247,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "adjusted_test_sample = transactions_modeler.prepare_data(transact_test_sample)\n",
        "\n",
        "print(f\"Changed columns to:\\n{adjusted_test_sample.dtypes}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mNU-laLUzkMC",
        "outputId": "4dc0d697-0fac-4002-f1ae-1cc2fba0e1f0"
      },
      "execution_count": 248,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Changed columns to:\n",
            "amount              float64\n",
            "transaction_date    float64\n",
            "dtype: object\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Expected Output: <br>\n",
        "Changed columns to:\n",
        "\n",
        "| Column Name        | Data Type |\n",
        "|--------------------|-----------|\n",
        "| amount             | float64   |\n",
        "| transaction_date   | float64   |\n",
        "\n",
        "dtype: object\n"
      ],
      "metadata": {
        "id": "NXhu8KxpzqS1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "filled_test_sample = transactions_modeler.impute_missing(adjusted_test_sample)\n",
        "\n",
        "print(f\"Imputed missing as mean:\\n{filled_test_sample}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0w_x7afYzl3M",
        "outputId": "936e2c96-5116-4bb6-c55c-4e24e87e6de3"
      },
      "execution_count": 249,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Imputed missing as mean:\n",
            "   customer_id  amount  transaction_date\n",
            "0           21   0.500      1.643674e+18\n",
            "1           22   3.375      1.667261e+18\n",
            "2           23   8.000      1.654042e+18\n",
            "3           24   3.000      1.652162e+18\n",
            "4           25   2.000      1.643674e+18\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Expected Output:<br>\n",
        "Imputed missing as mean:\n",
        "\n",
        "| customer_id | amount | transaction_date |\n",
        "|-------------|--------|------------------|\n",
        "| 21          | 0.5000 | 1.643674e+18     |\n",
        "| 22          | 3.8375 | 1.667261e+18     |\n",
        "| 23          | 8.0000 | 1.654042e+18     |\n",
        "| 24          | 3.0000 | 1.650845e+18     |\n",
        "| 25          | 2.0000 | 1.643674e+18     |\n"
      ],
      "metadata": {
        "id": "u4OR_uW40HHk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "oos_predictions = transactions_modeler.predict(filled_test_sample)\n",
        "print(f\"Predicted on out of sample data: {oos_predictions}\\n\")\n",
        "print(f'Accuracy = {sum(oos_predictions == [False, True, True, False, False])/.05}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fFjLOawL0OU2",
        "outputId": "16836684-0f4b-4175-b45a-a936a5021e07"
      },
      "execution_count": 250,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted on out of sample data: [False  True  True False False]\n",
            "\n",
            "Accuracy = 100.0%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "`Expected Output`\n",
        "Predicted on out of sample data: <br>\n",
        "[False True True False False] ([0 1 1 0 0])\n",
        "Accuracy = 100.0%"
      ],
      "metadata": {
        "id": "bsjDIfQX0Qi9"
      }
    }
  ]
}
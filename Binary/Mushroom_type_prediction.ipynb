{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":76727,"databundleVersionId":9045607,"sourceType":"competition"}],"dockerImageVersionId":30746,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-08-31T18:22:12.077929Z","iopub.execute_input":"2024-08-31T18:22:12.078361Z","iopub.status.idle":"2024-08-31T18:22:12.087738Z","shell.execute_reply.started":"2024-08-31T18:22:12.078325Z","shell.execute_reply":"2024-08-31T18:22:12.086468Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stdout","text":"/kaggle/input/playground-series-s4e8/sample_submission.csv\n/kaggle/input/playground-series-s4e8/train.csv\n/kaggle/input/playground-series-s4e8/test.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"df_sub=pd.read_csv(\"/kaggle/input/playground-series-s4e8/sample_submission.csv\")\ndf_train=pd.read_csv(\"/kaggle/input/playground-series-s4e8/train.csv\")\ndf_test=pd.read_csv(\"/kaggle/input/playground-series-s4e8/test.csv\")","metadata":{"execution":{"iopub.status.busy":"2024-08-31T18:22:12.090825Z","iopub.execute_input":"2024-08-31T18:22:12.091676Z","iopub.status.idle":"2024-08-31T18:22:28.375096Z","shell.execute_reply.started":"2024-08-31T18:22:12.091629Z","shell.execute_reply":"2024-08-31T18:22:28.373799Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.impute import SimpleImputer\nfrom sklearn import preprocessing\nfrom sklearn.model_selection import train_test_split\nimport optuna\nimport lightgbm as lgb\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import accuracy_score, classification_report, matthews_corrcoef\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"execution":{"iopub.status.busy":"2024-08-31T18:57:48.039534Z","iopub.execute_input":"2024-08-31T18:57:48.040023Z","iopub.status.idle":"2024-08-31T18:57:48.047210Z","shell.execute_reply.started":"2024-08-31T18:57:48.039990Z","shell.execute_reply":"2024-08-31T18:57:48.046090Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"code","source":"df_train.head()","metadata":{"execution":{"iopub.status.busy":"2024-08-31T18:22:28.386455Z","iopub.execute_input":"2024-08-31T18:22:28.386795Z","iopub.status.idle":"2024-08-31T18:22:28.420462Z","shell.execute_reply.started":"2024-08-31T18:22:28.386766Z","shell.execute_reply":"2024-08-31T18:22:28.419027Z"},"trusted":true},"execution_count":26,"outputs":[{"execution_count":26,"output_type":"execute_result","data":{"text/plain":"   id class  cap-diameter cap-shape cap-surface cap-color  \\\n0   0     e          8.80         f           s         u   \n1   1     p          4.51         x           h         o   \n2   2     e          6.94         f           s         b   \n3   3     e          3.88         f           y         g   \n4   4     e          5.85         x           l         w   \n\n  does-bruise-or-bleed gill-attachment gill-spacing gill-color  ...  \\\n0                    f               a            c          w  ...   \n1                    f               a            c          n  ...   \n2                    f               x            c          w  ...   \n3                    f               s          NaN          g  ...   \n4                    f               d          NaN          w  ...   \n\n   stem-root  stem-surface stem-color veil-type veil-color has-ring ring-type  \\\n0        NaN           NaN          w       NaN        NaN        f         f   \n1        NaN             y          o       NaN        NaN        t         z   \n2        NaN             s          n       NaN        NaN        f         f   \n3        NaN           NaN          w       NaN        NaN        f         f   \n4        NaN           NaN          w       NaN        NaN        f         f   \n\n  spore-print-color habitat season  \n0               NaN       d      a  \n1               NaN       d      w  \n2               NaN       l      w  \n3               NaN       d      u  \n4               NaN       g      a  \n\n[5 rows x 22 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>class</th>\n      <th>cap-diameter</th>\n      <th>cap-shape</th>\n      <th>cap-surface</th>\n      <th>cap-color</th>\n      <th>does-bruise-or-bleed</th>\n      <th>gill-attachment</th>\n      <th>gill-spacing</th>\n      <th>gill-color</th>\n      <th>...</th>\n      <th>stem-root</th>\n      <th>stem-surface</th>\n      <th>stem-color</th>\n      <th>veil-type</th>\n      <th>veil-color</th>\n      <th>has-ring</th>\n      <th>ring-type</th>\n      <th>spore-print-color</th>\n      <th>habitat</th>\n      <th>season</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>e</td>\n      <td>8.80</td>\n      <td>f</td>\n      <td>s</td>\n      <td>u</td>\n      <td>f</td>\n      <td>a</td>\n      <td>c</td>\n      <td>w</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>w</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>f</td>\n      <td>f</td>\n      <td>NaN</td>\n      <td>d</td>\n      <td>a</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>p</td>\n      <td>4.51</td>\n      <td>x</td>\n      <td>h</td>\n      <td>o</td>\n      <td>f</td>\n      <td>a</td>\n      <td>c</td>\n      <td>n</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>y</td>\n      <td>o</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>t</td>\n      <td>z</td>\n      <td>NaN</td>\n      <td>d</td>\n      <td>w</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>e</td>\n      <td>6.94</td>\n      <td>f</td>\n      <td>s</td>\n      <td>b</td>\n      <td>f</td>\n      <td>x</td>\n      <td>c</td>\n      <td>w</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>s</td>\n      <td>n</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>f</td>\n      <td>f</td>\n      <td>NaN</td>\n      <td>l</td>\n      <td>w</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>e</td>\n      <td>3.88</td>\n      <td>f</td>\n      <td>y</td>\n      <td>g</td>\n      <td>f</td>\n      <td>s</td>\n      <td>NaN</td>\n      <td>g</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>w</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>f</td>\n      <td>f</td>\n      <td>NaN</td>\n      <td>d</td>\n      <td>u</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>e</td>\n      <td>5.85</td>\n      <td>x</td>\n      <td>l</td>\n      <td>w</td>\n      <td>f</td>\n      <td>d</td>\n      <td>NaN</td>\n      <td>w</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>w</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>f</td>\n      <td>f</td>\n      <td>NaN</td>\n      <td>g</td>\n      <td>a</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 22 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"new_columns = {'class': 'class','cap-diameter':'cap_diameter','cap-shape':'cap_shape','cap-surface':'cap_surface',\n             'cap-color':'cap_color','does-bruise-or-bleed':'does_bruise_or_bleed','gill-attachment':'gill_attachment',\n            'gill-spacing':'gill_spacing','gill-color':'gill_color','stem-height':'stem_height','stem-width':'stem_width',\n            'stem-root':'stem_root','stem-surface':'stem_surface','stem-color':'stem_color','veil-type':'veil_type',\n            'veil-color':'veil_color','has-ring':'has_ring','ring-type':'ring_type','spore-print-color':'spore_print_color',\n            'habitat':'habitat','season':'season'}\ndf_train.rename(columns = new_columns, inplace = True)\ndf_train.columns","metadata":{"execution":{"iopub.status.busy":"2024-08-31T18:22:28.421855Z","iopub.execute_input":"2024-08-31T18:22:28.422418Z","iopub.status.idle":"2024-08-31T18:22:28.436106Z","shell.execute_reply.started":"2024-08-31T18:22:28.422378Z","shell.execute_reply":"2024-08-31T18:22:28.434934Z"},"trusted":true},"execution_count":27,"outputs":[{"execution_count":27,"output_type":"execute_result","data":{"text/plain":"Index(['id', 'class', 'cap_diameter', 'cap_shape', 'cap_surface', 'cap_color',\n       'does_bruise_or_bleed', 'gill_attachment', 'gill_spacing', 'gill_color',\n       'stem_height', 'stem_width', 'stem_root', 'stem_surface', 'stem_color',\n       'veil_type', 'veil_color', 'has_ring', 'ring_type', 'spore_print_color',\n       'habitat', 'season'],\n      dtype='object')"},"metadata":{}}]},{"cell_type":"code","source":"new_columns = {'class': 'class','cap-diameter':'cap_diameter','cap-shape':'cap_shape','cap-surface':'cap_surface',\n             'cap-color':'cap_color','does-bruise-or-bleed':'does_bruise_or_bleed','gill-attachment':'gill_attachment',\n            'gill-spacing':'gill_spacing','gill-color':'gill_color','stem-height':'stem_height','stem-width':'stem_width',\n            'stem-root':'stem_root','stem-surface':'stem_surface','stem-color':'stem_color','veil-type':'veil_type',\n            'veil-color':'veil_color','has-ring':'has_ring','ring-type':'ring_type','spore-print-color':'spore_print_color','habitat':'habitat','season':'season'}\ndf_test.rename(columns = new_columns, inplace = True )\ndf_test.columns","metadata":{"execution":{"iopub.status.busy":"2024-08-31T18:22:28.439944Z","iopub.execute_input":"2024-08-31T18:22:28.440435Z","iopub.status.idle":"2024-08-31T18:22:28.455099Z","shell.execute_reply.started":"2024-08-31T18:22:28.440393Z","shell.execute_reply":"2024-08-31T18:22:28.453982Z"},"trusted":true},"execution_count":28,"outputs":[{"execution_count":28,"output_type":"execute_result","data":{"text/plain":"Index(['id', 'cap_diameter', 'cap_shape', 'cap_surface', 'cap_color',\n       'does_bruise_or_bleed', 'gill_attachment', 'gill_spacing', 'gill_color',\n       'stem_height', 'stem_width', 'stem_root', 'stem_surface', 'stem_color',\n       'veil_type', 'veil_color', 'has_ring', 'ring_type', 'spore_print_color',\n       'habitat', 'season'],\n      dtype='object')"},"metadata":{}}]},{"cell_type":"code","source":"#Removing columns with more than 80% null values\ndf_train.drop(['veil_type','spore_print_color','stem_root','veil_color'], axis =1, inplace = True)","metadata":{"execution":{"iopub.status.busy":"2024-08-31T18:22:28.456586Z","iopub.execute_input":"2024-08-31T18:22:28.456974Z","iopub.status.idle":"2024-08-31T18:22:28.998924Z","shell.execute_reply.started":"2024-08-31T18:22:28.456942Z","shell.execute_reply":"2024-08-31T18:22:28.997763Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"col_name = ['cap_diameter', 'stem_height', 'stem_width']\n\ndef outlier_thresholds(df_train, col_name, q1=0.01, q3=0.99):\n    quartile1 = df_train[col_name].quantile(q1)\n    quartile3 = df_train[col_name].quantile(q3)\n    interquantile_range = quartile3 - quartile1\n    up_limit = quartile3 + 1.5 * interquantile_range\n    low_limit = quartile1 - 1.5 * interquantile_range\n    return low_limit, up_limit\n\ndef check_outlier(df_train, col_name):\n    low_limit, up_limit = outlier_thresholds(df_train, col_name)\n    if df_train[(df_train[col_name] > up_limit) | (df_train[col_name] < low_limit)].any(axis=None):\n        return True\n    else:\n        return False\n    \ndef replace_with_thresholds(df_train, variable):\n    low_limit, up_limit = outlier_thresholds(df_train, variable)\n    df_train.loc[(df_train[variable] < low_limit), variable] = low_limit\n    df_train.loc[(df_train[variable] > up_limit), variable] = up_limit","metadata":{"execution":{"iopub.status.busy":"2024-08-31T18:22:29.000420Z","iopub.execute_input":"2024-08-31T18:22:29.000773Z","iopub.status.idle":"2024-08-31T18:22:29.010768Z","shell.execute_reply.started":"2024-08-31T18:22:29.000742Z","shell.execute_reply":"2024-08-31T18:22:29.009568Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"from sklearn.impute import SimpleImputer\n\nfilled_df = df_train.copy()\nnum_cols = filled_df.select_dtypes(include=['number']).columns\ncat_cols = filled_df.select_dtypes(include=['object']).columns\n\nnumeric_imputer = SimpleImputer(strategy='median') \nfilled_df[num_cols] = numeric_imputer.fit_transform(filled_df[num_cols])\n\ncategorical_imputer = SimpleImputer(strategy='most_frequent')\nfilled_df[cat_cols] = categorical_imputer.fit_transform(filled_df[cat_cols])","metadata":{"execution":{"iopub.status.busy":"2024-08-31T18:22:29.012290Z","iopub.execute_input":"2024-08-31T18:22:29.012722Z","iopub.status.idle":"2024-08-31T18:22:41.955257Z","shell.execute_reply.started":"2024-08-31T18:22:29.012682Z","shell.execute_reply":"2024-08-31T18:22:41.954104Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"# Drop the 'id' column and encode categorical features\ncategorical_cols = [\n    'cap_shape', 'cap_surface', 'cap_color', 'does_bruise_or_bleed',\n    'gill_attachment', 'gill_spacing', 'gill_color', 'stem_surface',\n    'stem_color', 'has_ring', 'ring_type', 'habitat', 'season'\n]","metadata":{"execution":{"iopub.status.busy":"2024-08-31T18:22:41.956913Z","iopub.execute_input":"2024-08-31T18:22:41.957243Z","iopub.status.idle":"2024-08-31T18:22:41.962460Z","shell.execute_reply.started":"2024-08-31T18:22:41.957216Z","shell.execute_reply":"2024-08-31T18:22:41.961245Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"# numeric value and output column name : median\n\nfor col in categorical_cols:\n  print(col, \":\", filled_df[col].mode()[0])\n","metadata":{"execution":{"iopub.status.busy":"2024-08-31T18:22:41.963811Z","iopub.execute_input":"2024-08-31T18:22:41.964148Z","iopub.status.idle":"2024-08-31T18:22:47.413509Z","shell.execute_reply.started":"2024-08-31T18:22:41.964119Z","shell.execute_reply":"2024-08-31T18:22:47.412383Z"},"trusted":true},"execution_count":33,"outputs":[{"name":"stdout","text":"cap_shape : x\ncap_surface : t\ncap_color : n\ndoes_bruise_or_bleed : f\ngill_attachment : a\ngill_spacing : c\ngill_color : w\nstem_surface : s\nstem_color : w\nhas_ring : f\nring_type : f\nhabitat : d\nseason : a\n","output_type":"stream"}]},{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.preprocessing import LabelEncoder\n# Assuming 'train' DataFrame and 'categorical_cols' list are already defined\n\n# Iterate over categorical columns and encode them\nfor col in categorical_cols:\n  label_encoder = LabelEncoder()\n  filled_df[col] = label_encoder.fit_transform(filled_df[col])\n\n# Encode the target column\nle_target = LabelEncoder()\nfilled_df['class'] = le_target.fit_transform(filled_df['class'])\n\nprint(filled_df.info())","metadata":{"execution":{"iopub.status.busy":"2024-08-31T18:22:47.415380Z","iopub.execute_input":"2024-08-31T18:22:47.415826Z","iopub.status.idle":"2024-08-31T18:22:58.945232Z","shell.execute_reply.started":"2024-08-31T18:22:47.415786Z","shell.execute_reply":"2024-08-31T18:22:58.944136Z"},"trusted":true},"execution_count":34,"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 3116945 entries, 0 to 3116944\nData columns (total 18 columns):\n #   Column                Dtype  \n---  ------                -----  \n 0   id                    float64\n 1   class                 int64  \n 2   cap_diameter          float64\n 3   cap_shape             int64  \n 4   cap_surface           int64  \n 5   cap_color             int64  \n 6   does_bruise_or_bleed  int64  \n 7   gill_attachment       int64  \n 8   gill_spacing          int64  \n 9   gill_color            int64  \n 10  stem_height           float64\n 11  stem_width            float64\n 12  stem_surface          int64  \n 13  stem_color            int64  \n 14  has_ring              int64  \n 15  ring_type             int64  \n 16  habitat               int64  \n 17  season                int64  \ndtypes: float64(4), int64(14)\nmemory usage: 428.0 MB\nNone\n","output_type":"stream"}]},{"cell_type":"code","source":"# Separate features and target\nX = filled_df.drop(['class','id'], axis=1)\ny = filled_df['class']\n\n# Split the data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2024-08-31T18:22:58.946378Z","iopub.execute_input":"2024-08-31T18:22:58.946711Z","iopub.status.idle":"2024-08-31T18:23:00.247404Z","shell.execute_reply.started":"2024-08-31T18:22:58.946682Z","shell.execute_reply":"2024-08-31T18:23:00.246350Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"def objective(trial):\n    params = {\n        'objective': 'binary',\n        'metric': 'binary_logloss',\n        'boosting_type': 'gbdt',\n        'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 1e-1),\n        'num_leaves': trial.suggest_int('num_leaves', 20, 100),\n        'max_depth': trial.suggest_int('max_depth', -1, 50),\n        'min_child_samples': trial.suggest_int('min_child_samples', 1, 20),\n        'subsample': trial.suggest_uniform('subsample', 0.5, 1.0),\n        'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.5, 1.0),\n        'lambda_l1': trial.suggest_loguniform('lambda_l1', 1e-3, 1e2),      \n        'lambda_l2': trial.suggest_loguniform('lambda_l2', 1e-3, 1e2),\n        'seed': 42\n    }\n\n\n    # Create LightGBM dataset\n    train_data = lgb.Dataset(X_train, label=y_train)\n    # print(train_data.data.info())\n    test_data = lgb.Dataset(X_test, label=y_test, reference=train_data)\n    # print(test_data.data.info())\n\n    # Train the model\n    model = lgb.train(params, train_data, valid_sets=[test_data])\n\n    # Make predictions\n    y_pred = model.predict(X_test, num_iteration=model.best_iteration)\n    y_pred_binary = (y_pred > 0.5).astype(int)\n\n    # Calculate the accuracy\n    accuracy = accuracy_score(y_test, y_pred_binary)\n\n    return accuracy","metadata":{"execution":{"iopub.status.busy":"2024-08-31T18:23:00.248664Z","iopub.execute_input":"2024-08-31T18:23:00.248983Z","iopub.status.idle":"2024-08-31T18:23:00.260252Z","shell.execute_reply.started":"2024-08-31T18:23:00.248954Z","shell.execute_reply":"2024-08-31T18:23:00.259033Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"# Create an Optuna study\nstudy = optuna.create_study(direction='maximize')\nstudy.optimize(objective, n_trials=50)  # Adjust the number of trials as needed\n\n# Print the best parameters\nbest_params = study.best_params\nprint(\"Best Parameters:\", best_params)\n","metadata":{"execution":{"iopub.status.busy":"2024-08-31T18:23:00.264414Z","iopub.execute_input":"2024-08-31T18:23:00.264825Z","iopub.status.idle":"2024-08-31T18:53:43.415842Z","shell.execute_reply.started":"2024-08-31T18:23:00.264791Z","shell.execute_reply":"2024-08-31T18:53:43.414587Z"},"trusted":true},"execution_count":37,"outputs":[{"name":"stderr","text":"[I 2024-08-31 18:23:00,272] A new study created in memory with name: no-name-3a79282e-11f5-47af-9a76-8881c148ca14\n","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Info] Number of positive: 1364404, number of negative: 1129152\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.215164 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 932\n[LightGBM] [Info] Number of data points in the train set: 2493556, number of used features: 16\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.547172 -> initscore=0.189251\n[LightGBM] [Info] Start training from score 0.189251\n","output_type":"stream"},{"name":"stderr","text":"[I 2024-08-31 18:23:16,666] Trial 0 finished with value: 0.70107589322237 and parameters: {'learning_rate': 0.008692955784097636, 'num_leaves': 21, 'max_depth': 3, 'min_child_samples': 9, 'subsample': 0.7302588929162503, 'colsample_bytree': 0.9339144888996918, 'lambda_l1': 0.15454804678575082, 'lambda_l2': 0.2318191510319676}. Best is trial 0 with value: 0.70107589322237.\n","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Info] Number of positive: 1364404, number of negative: 1129152\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.458145 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 932\n[LightGBM] [Info] Number of data points in the train set: 2493556, number of used features: 16\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.547172 -> initscore=0.189251\n[LightGBM] [Info] Start training from score 0.189251\n","output_type":"stream"},{"name":"stderr","text":"[I 2024-08-31 18:23:56,794] Trial 1 finished with value: 0.9899452829613612 and parameters: {'learning_rate': 0.0882991272399762, 'num_leaves': 91, 'max_depth': 43, 'min_child_samples': 5, 'subsample': 0.5140607213080992, 'colsample_bytree': 0.6379042199462314, 'lambda_l1': 0.047548316480607124, 'lambda_l2': 9.60438610017564}. Best is trial 1 with value: 0.9899452829613612.\n","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Info] Number of positive: 1364404, number of negative: 1129152\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.419731 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 932\n[LightGBM] [Info] Number of data points in the train set: 2493556, number of used features: 16\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.547172 -> initscore=0.189251\n[LightGBM] [Info] Start training from score 0.189251\n","output_type":"stream"},{"name":"stderr","text":"[I 2024-08-31 18:24:38,619] Trial 2 finished with value: 0.9820914388928903 and parameters: {'learning_rate': 0.010141006552347424, 'num_leaves': 97, 'max_depth': 36, 'min_child_samples': 17, 'subsample': 0.9653307030404371, 'colsample_bytree': 0.6994141078874108, 'lambda_l1': 0.01866590725478874, 'lambda_l2': 0.0021904358532587654}. Best is trial 1 with value: 0.9899452829613612.\n","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Info] Number of positive: 1364404, number of negative: 1129152\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.438986 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 932\n[LightGBM] [Info] Number of data points in the train set: 2493556, number of used features: 16\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.547172 -> initscore=0.189251\n[LightGBM] [Info] Start training from score 0.189251\n","output_type":"stream"},{"name":"stderr","text":"[I 2024-08-31 18:25:18,790] Trial 3 finished with value: 0.9801199572016831 and parameters: {'learning_rate': 0.011587596099305259, 'num_leaves': 86, 'max_depth': 36, 'min_child_samples': 12, 'subsample': 0.8742976593114041, 'colsample_bytree': 0.7442959670615736, 'lambda_l1': 92.01711708752161, 'lambda_l2': 11.049919347937063}. Best is trial 1 with value: 0.9899452829613612.\n","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Info] Number of positive: 1364404, number of negative: 1129152\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.178697 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 932\n[LightGBM] [Info] Number of data points in the train set: 2493556, number of used features: 16\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.547172 -> initscore=0.189251\n[LightGBM] [Info] Start training from score 0.189251\n","output_type":"stream"},{"name":"stderr","text":"[I 2024-08-31 18:25:51,203] Trial 4 finished with value: 0.9811337704066001 and parameters: {'learning_rate': 0.033399626057123606, 'num_leaves': 82, 'max_depth': 9, 'min_child_samples': 8, 'subsample': 0.6309926086701096, 'colsample_bytree': 0.961678134036168, 'lambda_l1': 0.0255483362096881, 'lambda_l2': 38.72958962861395}. Best is trial 1 with value: 0.9899452829613612.\n","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Info] Number of positive: 1364404, number of negative: 1129152\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.443297 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 932\n[LightGBM] [Info] Number of data points in the train set: 2493556, number of used features: 16\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.547172 -> initscore=0.189251\n[LightGBM] [Info] Start training from score 0.189251\n","output_type":"stream"},{"name":"stderr","text":"[I 2024-08-31 18:26:28,506] Trial 5 finished with value: 0.9830555239184522 and parameters: {'learning_rate': 0.025434072747653927, 'num_leaves': 64, 'max_depth': 16, 'min_child_samples': 8, 'subsample': 0.786569352287712, 'colsample_bytree': 0.685478886217181, 'lambda_l1': 0.8480312711136737, 'lambda_l2': 0.033309220152463355}. Best is trial 1 with value: 0.9899452829613612.\n","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Info] Number of positive: 1364404, number of negative: 1129152\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.179886 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 932\n[LightGBM] [Info] Number of data points in the train set: 2493556, number of used features: 16\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.547172 -> initscore=0.189251\n[LightGBM] [Info] Start training from score 0.189251\n","output_type":"stream"},{"name":"stderr","text":"[I 2024-08-31 18:27:03,409] Trial 6 finished with value: 0.9350983094023154 and parameters: {'learning_rate': 0.0016605797569330884, 'num_leaves': 74, 'max_depth': 27, 'min_child_samples': 18, 'subsample': 0.9609596114304291, 'colsample_bytree': 0.8028792272126098, 'lambda_l1': 0.011153768578570096, 'lambda_l2': 1.4667995626918624}. Best is trial 1 with value: 0.9899452829613612.\n","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Info] Number of positive: 1364404, number of negative: 1129152\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.141781 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 932\n[LightGBM] [Info] Number of data points in the train set: 2493556, number of used features: 16\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.547172 -> initscore=0.189251\n[LightGBM] [Info] Start training from score 0.189251\n","output_type":"stream"},{"name":"stderr","text":"[I 2024-08-31 18:27:37,216] Trial 7 finished with value: 0.9885721435572331 and parameters: {'learning_rate': 0.08702913257274676, 'num_leaves': 58, 'max_depth': -1, 'min_child_samples': 15, 'subsample': 0.9909441523333837, 'colsample_bytree': 0.5690327231058334, 'lambda_l1': 23.619561506809738, 'lambda_l2': 22.27015247839915}. Best is trial 1 with value: 0.9899452829613612.\n","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Info] Number of positive: 1364404, number of negative: 1129152\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.416765 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 932\n[LightGBM] [Info] Number of data points in the train set: 2493556, number of used features: 16\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.547172 -> initscore=0.189251\n[LightGBM] [Info] Start training from score 0.189251\n","output_type":"stream"},{"name":"stderr","text":"[I 2024-08-31 18:28:05,253] Trial 8 finished with value: 0.5469971398276197 and parameters: {'learning_rate': 0.0012041547572085132, 'num_leaves': 21, 'max_depth': 14, 'min_child_samples': 10, 'subsample': 0.8129998249942938, 'colsample_bytree': 0.6979446204207019, 'lambda_l1': 2.713278012307545, 'lambda_l2': 0.045732986722367815}. Best is trial 1 with value: 0.9899452829613612.\n","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Info] Number of positive: 1364404, number of negative: 1129152\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.178933 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 932\n[LightGBM] [Info] Number of data points in the train set: 2493556, number of used features: 16\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.547172 -> initscore=0.189251\n[LightGBM] [Info] Start training from score 0.189251\n","output_type":"stream"},{"name":"stderr","text":"[I 2024-08-31 18:28:41,514] Trial 9 finished with value: 0.8904103216450724 and parameters: {'learning_rate': 0.001076979605933462, 'num_leaves': 96, 'max_depth': -1, 'min_child_samples': 16, 'subsample': 0.5904832242932421, 'colsample_bytree': 0.9559412964985645, 'lambda_l1': 10.773337942739804, 'lambda_l2': 0.5453046548276232}. Best is trial 1 with value: 0.9899452829613612.\n","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Info] Number of positive: 1364404, number of negative: 1129152\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.141978 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 932\n[LightGBM] [Info] Number of data points in the train set: 2493556, number of used features: 16\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.547172 -> initscore=0.189251\n[LightGBM] [Info] Start training from score 0.189251\n","output_type":"stream"},{"name":"stderr","text":"[I 2024-08-31 18:29:12,382] Trial 10 finished with value: 0.9880989237859507 and parameters: {'learning_rate': 0.09531488611885858, 'num_leaves': 45, 'max_depth': 47, 'min_child_samples': 1, 'subsample': 0.5040334796440822, 'colsample_bytree': 0.5295616029116822, 'lambda_l1': 0.0024922337294041672, 'lambda_l2': 4.270668946444817}. Best is trial 1 with value: 0.9899452829613612.\n","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Info] Number of positive: 1364404, number of negative: 1129152\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.142917 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 932\n[LightGBM] [Info] Number of data points in the train set: 2493556, number of used features: 16\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.547172 -> initscore=0.189251\n[LightGBM] [Info] Start training from score 0.189251\n","output_type":"stream"},{"name":"stderr","text":"[I 2024-08-31 18:29:45,058] Trial 11 finished with value: 0.988402105266535 and parameters: {'learning_rate': 0.08469039387711137, 'num_leaves': 54, 'max_depth': 50, 'min_child_samples': 3, 'subsample': 0.6703938490960797, 'colsample_bytree': 0.5188236768569915, 'lambda_l1': 0.20686665875912047, 'lambda_l2': 97.75948968970211}. Best is trial 1 with value: 0.9899452829613612.\n","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Info] Number of positive: 1364404, number of negative: 1129152\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.421827 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 932\n[LightGBM] [Info] Number of data points in the train set: 2493556, number of used features: 16\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.547172 -> initscore=0.189251\n[LightGBM] [Info] Start training from score 0.189251\n","output_type":"stream"},{"name":"stderr","text":"[I 2024-08-31 18:30:18,543] Trial 12 finished with value: 0.9833218102982247 and parameters: {'learning_rate': 0.04412941463081498, 'num_leaves': 42, 'max_depth': 23, 'min_child_samples': 5, 'subsample': 0.5062857871416124, 'colsample_bytree': 0.6073796501245524, 'lambda_l1': 80.56609432026805, 'lambda_l2': 12.77780687568591}. Best is trial 1 with value: 0.9899452829613612.\n","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Info] Number of positive: 1364404, number of negative: 1129152\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.444186 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 932\n[LightGBM] [Info] Number of data points in the train set: 2493556, number of used features: 16\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.547172 -> initscore=0.189251\n[LightGBM] [Info] Start training from score 0.189251\n","output_type":"stream"},{"name":"stderr","text":"[I 2024-08-31 18:30:55,518] Trial 13 finished with value: 0.9870851105810337 and parameters: {'learning_rate': 0.05315997936948528, 'num_leaves': 62, 'max_depth': 40, 'min_child_samples': 14, 'subsample': 0.8804675260397727, 'colsample_bytree': 0.6033563224760359, 'lambda_l1': 8.918923245424844, 'lambda_l2': 3.0858866051714706}. Best is trial 1 with value: 0.9899452829613612.\n","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Info] Number of positive: 1364404, number of negative: 1129152\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.556180 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 932\n[LightGBM] [Info] Number of data points in the train set: 2493556, number of used features: 16\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.547172 -> initscore=0.189251\n[LightGBM] [Info] Start training from score 0.189251\n","output_type":"stream"},{"name":"stderr","text":"[I 2024-08-31 18:31:34,612] Trial 14 finished with value: 0.9834244749265707 and parameters: {'learning_rate': 0.02031850599198361, 'num_leaves': 74, 'max_depth': 27, 'min_child_samples': 20, 'subsample': 0.7138507376706188, 'colsample_bytree': 0.5945333347084255, 'lambda_l1': 0.08444557629947284, 'lambda_l2': 26.074437624114786}. Best is trial 1 with value: 0.9899452829613612.\n","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Info] Number of positive: 1364404, number of negative: 1129152\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.412724 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 932\n[LightGBM] [Info] Number of data points in the train set: 2493556, number of used features: 16\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.547172 -> initscore=0.189251\n[LightGBM] [Info] Start training from score 0.189251\n","output_type":"stream"},{"name":"stderr","text":"[I 2024-08-31 18:32:06,245] Trial 15 finished with value: 0.9833571012642186 and parameters: {'learning_rate': 0.05818080579491537, 'num_leaves': 35, 'max_depth': 20, 'min_child_samples': 6, 'subsample': 0.5695411965865302, 'colsample_bytree': 0.6316616147655445, 'lambda_l1': 0.0019414504232685742, 'lambda_l2': 72.18835716852539}. Best is trial 1 with value: 0.9899452829613612.\n","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Info] Number of positive: 1364404, number of negative: 1129152\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.177766 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 932\n[LightGBM] [Info] Number of data points in the train set: 2493556, number of used features: 16\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.547172 -> initscore=0.189251\n[LightGBM] [Info] Start training from score 0.189251\n","output_type":"stream"},{"name":"stderr","text":"[I 2024-08-31 18:32:38,628] Trial 16 finished with value: 0.9489804921164794 and parameters: {'learning_rate': 0.003327810892549865, 'num_leaves': 53, 'max_depth': 43, 'min_child_samples': 13, 'subsample': 0.8814589981536644, 'colsample_bytree': 0.8158075932810016, 'lambda_l1': 1.0526944065566113, 'lambda_l2': 0.7991229561892361}. Best is trial 1 with value: 0.9899452829613612.\n","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Info] Number of positive: 1364404, number of negative: 1129152\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.143781 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 932\n[LightGBM] [Info] Number of data points in the train set: 2493556, number of used features: 16\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.547172 -> initscore=0.189251\n[LightGBM] [Info] Start training from score 0.189251\n","output_type":"stream"},{"name":"stderr","text":"[I 2024-08-31 18:33:13,863] Trial 17 finished with value: 0.9836666992840747 and parameters: {'learning_rate': 0.018817493200042498, 'num_leaves': 76, 'max_depth': 32, 'min_child_samples': 15, 'subsample': 0.8108282417213085, 'colsample_bytree': 0.5351551873403952, 'lambda_l1': 17.66243153078998, 'lambda_l2': 0.0987045103000016}. Best is trial 1 with value: 0.9899452829613612.\n","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Info] Number of positive: 1364404, number of negative: 1129152\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.427485 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 932\n[LightGBM] [Info] Number of data points in the train set: 2493556, number of used features: 16\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.547172 -> initscore=0.189251\n[LightGBM] [Info] Start training from score 0.189251\n","output_type":"stream"},{"name":"stderr","text":"[I 2024-08-31 18:33:52,252] Trial 18 finished with value: 0.9789569594587008 and parameters: {'learning_rate': 0.005309885937704375, 'num_leaves': 89, 'max_depth': 11, 'min_child_samples': 5, 'subsample': 0.6600296542908293, 'colsample_bytree': 0.653415891815417, 'lambda_l1': 0.04649413291786953, 'lambda_l2': 7.273518197001343}. Best is trial 1 with value: 0.9899452829613612.\n","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Info] Number of positive: 1364404, number of negative: 1129152\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.146004 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 932\n[LightGBM] [Info] Number of data points in the train set: 2493556, number of used features: 16\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.547172 -> initscore=0.189251\n[LightGBM] [Info] Start training from score 0.189251\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","output_type":"stream"},{"name":"stderr","text":"[I 2024-08-31 18:34:18,270] Trial 19 finished with value: 0.9810118561604392 and parameters: {'learning_rate': 0.09814248096743573, 'num_leaves': 69, 'max_depth': 6, 'min_child_samples': 11, 'subsample': 0.9984469887069287, 'colsample_bytree': 0.5648949687177764, 'lambda_l1': 0.6516458554823639, 'lambda_l2': 2.0316928823712637}. Best is trial 1 with value: 0.9899452829613612.\n","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Info] Number of positive: 1364404, number of negative: 1129152\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.429354 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 932\n[LightGBM] [Info] Number of data points in the train set: 2493556, number of used features: 16\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.547172 -> initscore=0.189251\n[LightGBM] [Info] Start training from score 0.189251\n","output_type":"stream"},{"name":"stderr","text":"[I 2024-08-31 18:34:55,422] Trial 20 finished with value: 0.9842923118630582 and parameters: {'learning_rate': 0.037419294277757066, 'num_leaves': 54, 'max_depth': 31, 'min_child_samples': 2, 'subsample': 0.5700015720242225, 'colsample_bytree': 0.7701445228051111, 'lambda_l1': 0.005608865456008533, 'lambda_l2': 0.007723578414885772}. Best is trial 1 with value: 0.9899452829613612.\n","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Info] Number of positive: 1364404, number of negative: 1129152\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.140549 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 932\n[LightGBM] [Info] Number of data points in the train set: 2493556, number of used features: 16\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.547172 -> initscore=0.189251\n[LightGBM] [Info] Start training from score 0.189251\n","output_type":"stream"},{"name":"stderr","text":"[I 2024-08-31 18:35:28,061] Trial 21 finished with value: 0.9876208916102145 and parameters: {'learning_rate': 0.0669275281002852, 'num_leaves': 54, 'max_depth': 49, 'min_child_samples': 3, 'subsample': 0.6710032762760858, 'colsample_bytree': 0.5002309624341514, 'lambda_l1': 0.21778515147708302, 'lambda_l2': 68.15984290083341}. Best is trial 1 with value: 0.9899452829613612.\n","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Info] Number of positive: 1364404, number of negative: 1129152\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.145900 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 932\n[LightGBM] [Info] Number of data points in the train set: 2493556, number of used features: 16\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.547172 -> initscore=0.189251\n[LightGBM] [Info] Start training from score 0.189251\n","output_type":"stream"},{"name":"stderr","text":"[I 2024-08-31 18:36:00,248] Trial 22 finished with value: 0.9871941917486513 and parameters: {'learning_rate': 0.07505506360868308, 'num_leaves': 47, 'max_depth': 46, 'min_child_samples': 3, 'subsample': 0.6104292378296264, 'colsample_bytree': 0.5674960398277862, 'lambda_l1': 3.141696736208078, 'lambda_l2': 95.35366845419607}. Best is trial 1 with value: 0.9899452829613612.\n","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Info] Number of positive: 1364404, number of negative: 1129152\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.140866 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 932\n[LightGBM] [Info] Number of data points in the train set: 2493556, number of used features: 16\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.547172 -> initscore=0.189251\n[LightGBM] [Info] Start training from score 0.189251\n","output_type":"stream"},{"name":"stderr","text":"[I 2024-08-31 18:36:30,065] Trial 23 finished with value: 0.977750650075635 and parameters: {'learning_rate': 0.02903881872398375, 'num_leaves': 37, 'max_depth': 42, 'min_child_samples': 6, 'subsample': 0.6996013882508453, 'colsample_bytree': 0.5000350174513594, 'lambda_l1': 0.07241107012127249, 'lambda_l2': 20.45348913654475}. Best is trial 1 with value: 0.9899452829613612.\n","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Info] Number of positive: 1364404, number of negative: 1129152\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.415463 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 932\n[LightGBM] [Info] Number of data points in the train set: 2493556, number of used features: 16\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.547172 -> initscore=0.189251\n[LightGBM] [Info] Start training from score 0.189251\n","output_type":"stream"},{"name":"stderr","text":"[I 2024-08-31 18:37:07,111] Trial 24 finished with value: 0.9892635256637509 and parameters: {'learning_rate': 0.09510293809798144, 'num_leaves': 66, 'max_depth': 50, 'min_child_samples': 4, 'subsample': 0.5422980103675109, 'colsample_bytree': 0.6476387940001724, 'lambda_l1': 0.3271976158121376, 'lambda_l2': 31.574420628983496}. Best is trial 1 with value: 0.9899452829613612.\n","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Info] Number of positive: 1364404, number of negative: 1129152\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.416631 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 932\n[LightGBM] [Info] Number of data points in the train set: 2493556, number of used features: 16\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.547172 -> initscore=0.189251\n[LightGBM] [Info] Start training from score 0.189251\n","output_type":"stream"},{"name":"stderr","text":"[I 2024-08-31 18:37:45,282] Trial 25 finished with value: 0.9868332614146224 and parameters: {'learning_rate': 0.04936677646272159, 'num_leaves': 67, 'max_depth': 38, 'min_child_samples': 7, 'subsample': 0.5360108023553001, 'colsample_bytree': 0.6675763690524468, 'lambda_l1': 44.96516815369783, 'lambda_l2': 8.011031256291902}. Best is trial 1 with value: 0.9899452829613612.\n","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Info] Number of positive: 1364404, number of negative: 1129152\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.440875 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 932\n[LightGBM] [Info] Number of data points in the train set: 2493556, number of used features: 16\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.547172 -> initscore=0.189251\n[LightGBM] [Info] Start training from score 0.189251\n","output_type":"stream"},{"name":"stderr","text":"[I 2024-08-31 18:38:29,580] Trial 26 finished with value: 0.9889234490823546 and parameters: {'learning_rate': 0.06436380930967336, 'num_leaves': 100, 'max_depth': 43, 'min_child_samples': 4, 'subsample': 0.5474323543863042, 'colsample_bytree': 0.7414210879390892, 'lambda_l1': 2.5287901218871527, 'lambda_l2': 27.62403781810568}. Best is trial 1 with value: 0.9899452829613612.\n","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Info] Number of positive: 1364404, number of negative: 1129152\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.451528 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 932\n[LightGBM] [Info] Number of data points in the train set: 2493556, number of used features: 16\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.547172 -> initscore=0.189251\n[LightGBM] [Info] Start training from score 0.189251\n","output_type":"stream"},{"name":"stderr","text":"[I 2024-08-31 18:39:11,273] Trial 27 finished with value: 0.9828277367743095 and parameters: {'learning_rate': 0.013856772641572819, 'num_leaves': 99, 'max_depth': 44, 'min_child_samples': 4, 'subsample': 0.5448448831095521, 'colsample_bytree': 0.7312411601283103, 'lambda_l1': 0.4158291655868957, 'lambda_l2': 6.3387173032881705}. Best is trial 1 with value: 0.9899452829613612.\n","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Info] Number of positive: 1364404, number of negative: 1129152\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.175097 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 932\n[LightGBM] [Info] Number of data points in the train set: 2493556, number of used features: 16\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.547172 -> initscore=0.189251\n[LightGBM] [Info] Start training from score 0.189251\n","output_type":"stream"},{"name":"stderr","text":"[I 2024-08-31 18:39:49,836] Trial 28 finished with value: 0.9883026489078248 and parameters: {'learning_rate': 0.06399689308422533, 'num_leaves': 92, 'max_depth': 34, 'min_child_samples': 1, 'subsample': 0.5364555229251996, 'colsample_bytree': 0.9028684973169595, 'lambda_l1': 2.033399823140519, 'lambda_l2': 39.477363077330985}. Best is trial 1 with value: 0.9899452829613612.\n","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Info] Number of positive: 1364404, number of negative: 1129152\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.178280 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 932\n[LightGBM] [Info] Number of data points in the train set: 2493556, number of used features: 16\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.547172 -> initscore=0.189251\n[LightGBM] [Info] Start training from score 0.189251\n","output_type":"stream"},{"name":"stderr","text":"[I 2024-08-31 18:40:25,477] Trial 29 finished with value: 0.975517694409109 and parameters: {'learning_rate': 0.005911976848683616, 'num_leaves': 86, 'max_depth': 40, 'min_child_samples': 9, 'subsample': 0.6277057508511299, 'colsample_bytree': 0.8592856157215827, 'lambda_l1': 4.9766678939923175, 'lambda_l2': 0.2439677691169902}. Best is trial 1 with value: 0.9899452829613612.\n","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Info] Number of positive: 1364404, number of negative: 1129152\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.416856 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 932\n[LightGBM] [Info] Number of data points in the train set: 2493556, number of used features: 16\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.547172 -> initscore=0.189251\n[LightGBM] [Info] Start training from score 0.189251\n","output_type":"stream"},{"name":"stderr","text":"[I 2024-08-31 18:41:06,501] Trial 30 finished with value: 0.9864915806984083 and parameters: {'learning_rate': 0.03999304499608626, 'num_leaves': 81, 'max_depth': 50, 'min_child_samples': 5, 'subsample': 0.7493182695390717, 'colsample_bytree': 0.7226822528434933, 'lambda_l1': 0.11348402872205746, 'lambda_l2': 1.1738794361679195}. Best is trial 1 with value: 0.9899452829613612.\n","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Info] Number of positive: 1364404, number of negative: 1129152\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.415228 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 932\n[LightGBM] [Info] Number of data points in the train set: 2493556, number of used features: 16\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.547172 -> initscore=0.189251\n[LightGBM] [Info] Start training from score 0.189251\n","output_type":"stream"},{"name":"stderr","text":"[I 2024-08-31 18:41:46,867] Trial 31 finished with value: 0.9901249460609668 and parameters: {'learning_rate': 0.09991858082126771, 'num_leaves': 94, 'max_depth': 45, 'min_child_samples': 7, 'subsample': 0.5827144672326227, 'colsample_bytree': 0.6384783163474341, 'lambda_l1': 1.4980583835554424, 'lambda_l2': 15.884487362049208}. Best is trial 31 with value: 0.9901249460609668.\n","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Info] Number of positive: 1364404, number of negative: 1129152\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.427038 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 932\n[LightGBM] [Info] Number of data points in the train set: 2493556, number of used features: 16\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.547172 -> initscore=0.189251\n[LightGBM] [Info] Start training from score 0.189251\n","output_type":"stream"},{"name":"stderr","text":"[I 2024-08-31 18:42:27,460] Trial 32 finished with value: 0.9893453365394641 and parameters: {'learning_rate': 0.06874358715948099, 'num_leaves': 94, 'max_depth': 45, 'min_child_samples': 7, 'subsample': 0.573715053199984, 'colsample_bytree': 0.6390361821843491, 'lambda_l1': 1.36107342216163, 'lambda_l2': 15.301366038929316}. Best is trial 31 with value: 0.9901249460609668.\n","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Info] Number of positive: 1364404, number of negative: 1129152\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.410419 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 932\n[LightGBM] [Info] Number of data points in the train set: 2493556, number of used features: 16\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.547172 -> initscore=0.189251\n[LightGBM] [Info] Start training from score 0.189251\n","output_type":"stream"},{"name":"stderr","text":"[I 2024-08-31 18:43:07,638] Trial 33 finished with value: 0.9894030853929088 and parameters: {'learning_rate': 0.07083387524735858, 'num_leaves': 92, 'max_depth': 47, 'min_child_samples': 8, 'subsample': 0.5906528805351877, 'colsample_bytree': 0.6426696737239533, 'lambda_l1': 0.38690858436675074, 'lambda_l2': 2.765857111451238}. Best is trial 31 with value: 0.9901249460609668.\n","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Info] Number of positive: 1364404, number of negative: 1129152\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.431645 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 932\n[LightGBM] [Info] Number of data points in the train set: 2493556, number of used features: 16\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.547172 -> initscore=0.189251\n[LightGBM] [Info] Start training from score 0.189251\n","output_type":"stream"},{"name":"stderr","text":"[I 2024-08-31 18:43:48,512] Trial 34 finished with value: 0.9881550685045773 and parameters: {'learning_rate': 0.04710054818173564, 'num_leaves': 93, 'max_depth': 37, 'min_child_samples': 8, 'subsample': 0.5958344937760034, 'colsample_bytree': 0.6224072230567516, 'lambda_l1': 1.1380626482303615, 'lambda_l2': 2.3568975855365046}. Best is trial 31 with value: 0.9901249460609668.\n","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Info] Number of positive: 1364404, number of negative: 1129152\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.432162 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 932\n[LightGBM] [Info] Number of data points in the train set: 2493556, number of used features: 16\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.547172 -> initscore=0.189251\n[LightGBM] [Info] Start training from score 0.189251\n","output_type":"stream"},{"name":"stderr","text":"[I 2024-08-31 18:44:28,022] Trial 35 finished with value: 0.9845489734339233 and parameters: {'learning_rate': 0.023758798703822012, 'num_leaves': 82, 'max_depth': 46, 'min_child_samples': 10, 'subsample': 0.6223237598327469, 'colsample_bytree': 0.6701711991162164, 'lambda_l1': 0.03477519292959213, 'lambda_l2': 11.22418712986194}. Best is trial 31 with value: 0.9901249460609668.\n","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Info] Number of positive: 1364404, number of negative: 1129152\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.421192 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 932\n[LightGBM] [Info] Number of data points in the train set: 2493556, number of used features: 16\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.547172 -> initscore=0.189251\n[LightGBM] [Info] Start training from score 0.189251\n","output_type":"stream"},{"name":"stderr","text":"[I 2024-08-31 18:45:08,634] Trial 36 finished with value: 0.989123965934593 and parameters: {'learning_rate': 0.06981365763713376, 'num_leaves': 88, 'max_depth': 39, 'min_child_samples': 7, 'subsample': 0.6461156374795098, 'colsample_bytree': 0.7107879077115273, 'lambda_l1': 0.011872443218406066, 'lambda_l2': 4.072373873719893}. Best is trial 31 with value: 0.9901249460609668.\n","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Info] Number of positive: 1364404, number of negative: 1129152\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.428266 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 932\n[LightGBM] [Info] Number of data points in the train set: 2493556, number of used features: 16\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.547172 -> initscore=0.189251\n[LightGBM] [Info] Start training from score 0.189251\n","output_type":"stream"},{"name":"stderr","text":"[I 2024-08-31 18:45:50,549] Trial 37 finished with value: 0.9866680355283779 and parameters: {'learning_rate': 0.03570334988190326, 'num_leaves': 94, 'max_depth': 46, 'min_child_samples': 8, 'subsample': 0.5794770055002869, 'colsample_bytree': 0.7742694625551341, 'lambda_l1': 0.48139425427971877, 'lambda_l2': 0.3926929084984317}. Best is trial 31 with value: 0.9901249460609668.\n","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Info] Number of positive: 1364404, number of negative: 1129152\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.417424 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 932\n[LightGBM] [Info] Number of data points in the train set: 2493556, number of used features: 16\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.547172 -> initscore=0.189251\n[LightGBM] [Info] Start training from score 0.189251\n","output_type":"stream"},{"name":"stderr","text":"[I 2024-08-31 18:46:30,805] Trial 38 finished with value: 0.9814369518871844 and parameters: {'learning_rate': 0.015114823184305836, 'num_leaves': 80, 'max_depth': 35, 'min_child_samples': 11, 'subsample': 0.5055196874321047, 'colsample_bytree': 0.6833018797757093, 'lambda_l1': 1.3915091259603138, 'lambda_l2': 15.201694103631663}. Best is trial 31 with value: 0.9901249460609668.\n","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Info] Number of positive: 1364404, number of negative: 1129152\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.448712 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 932\n[LightGBM] [Info] Number of data points in the train set: 2493556, number of used features: 16\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.547172 -> initscore=0.189251\n[LightGBM] [Info] Start training from score 0.189251\n","output_type":"stream"},{"name":"stderr","text":"[I 2024-08-31 18:47:09,922] Trial 39 finished with value: 0.9812989962928444 and parameters: {'learning_rate': 0.007986161279827075, 'num_leaves': 90, 'max_depth': 30, 'min_child_samples': 9, 'subsample': 0.6954586675352163, 'colsample_bytree': 0.6394483066730556, 'lambda_l1': 0.16499178484824417, 'lambda_l2': 0.0013472455116513165}. Best is trial 31 with value: 0.9901249460609668.\n","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Info] Number of positive: 1364404, number of negative: 1129152\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.145199 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 932\n[LightGBM] [Info] Number of data points in the train set: 2493556, number of used features: 16\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.547172 -> initscore=0.189251\n[LightGBM] [Info] Start training from score 0.189251\n","output_type":"stream"},{"name":"stderr","text":"[I 2024-08-31 18:47:47,451] Trial 40 finished with value: 0.9874332078365194 and parameters: {'learning_rate': 0.03171757624599874, 'num_leaves': 96, 'max_depth': 41, 'min_child_samples': 6, 'subsample': 0.6006828392648205, 'colsample_bytree': 0.5846678916655474, 'lambda_l1': 4.787269521600435, 'lambda_l2': 5.1601112172752615}. Best is trial 31 with value: 0.9901249460609668.\n","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Info] Number of positive: 1364404, number of negative: 1129152\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.418192 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 932\n[LightGBM] [Info] Number of data points in the train set: 2493556, number of used features: 16\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.547172 -> initscore=0.189251\n[LightGBM] [Info] Start training from score 0.189251\n","output_type":"stream"},{"name":"stderr","text":"[I 2024-08-31 18:48:27,366] Trial 41 finished with value: 0.9898041190973854 and parameters: {'learning_rate': 0.09665195234771118, 'num_leaves': 85, 'max_depth': 48, 'min_child_samples': 7, 'subsample': 0.5632241047155988, 'colsample_bytree': 0.6579658787157201, 'lambda_l1': 0.30041753099610347, 'lambda_l2': 10.836784482588804}. Best is trial 31 with value: 0.9901249460609668.\n","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Info] Number of positive: 1364404, number of negative: 1129152\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.428643 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 932\n[LightGBM] [Info] Number of data points in the train set: 2493556, number of used features: 16\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.547172 -> initscore=0.189251\n[LightGBM] [Info] Start training from score 0.189251\n","output_type":"stream"},{"name":"stderr","text":"[I 2024-08-31 18:49:08,323] Trial 42 finished with value: 0.9891127369908677 and parameters: {'learning_rate': 0.07672579214107533, 'num_leaves': 85, 'max_depth': 47, 'min_child_samples': 7, 'subsample': 0.5599492441425785, 'colsample_bytree': 0.6887612513341282, 'lambda_l1': 0.679317157336643, 'lambda_l2': 42.25118737200863}. Best is trial 31 with value: 0.9901249460609668.\n","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Info] Number of positive: 1364404, number of negative: 1129152\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.431756 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 932\n[LightGBM] [Info] Number of data points in the train set: 2493556, number of used features: 16\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.547172 -> initscore=0.189251\n[LightGBM] [Info] Start training from score 0.189251\n","output_type":"stream"},{"name":"stderr","text":"[I 2024-08-31 18:49:48,566] Trial 43 finished with value: 0.9902436520374919 and parameters: {'learning_rate': 0.09943374006831812, 'num_leaves': 96, 'max_depth': 44, 'min_child_samples': 9, 'subsample': 0.5152035016315561, 'colsample_bytree': 0.61989603038884, 'lambda_l1': 0.019927227883067753, 'lambda_l2': 1.3313115689406765}. Best is trial 43 with value: 0.9902436520374919.\n","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Info] Number of positive: 1364404, number of negative: 1129152\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.427086 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 932\n[LightGBM] [Info] Number of data points in the train set: 2493556, number of used features: 16\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.547172 -> initscore=0.189251\n[LightGBM] [Info] Start training from score 0.189251\n","output_type":"stream"},{"name":"stderr","text":"[I 2024-08-31 18:50:28,639] Trial 44 finished with value: 0.9902532768463993 and parameters: {'learning_rate': 0.09694442884161596, 'num_leaves': 100, 'max_depth': 43, 'min_child_samples': 12, 'subsample': 0.5204567686598147, 'colsample_bytree': 0.6167041312178044, 'lambda_l1': 0.020554267538122065, 'lambda_l2': 1.3412992340902163}. Best is trial 44 with value: 0.9902532768463993.\n","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Info] Number of positive: 1364404, number of negative: 1129152\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.441433 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 932\n[LightGBM] [Info] Number of data points in the train set: 2493556, number of used features: 16\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.547172 -> initscore=0.189251\n[LightGBM] [Info] Start training from score 0.189251\n","output_type":"stream"},{"name":"stderr","text":"[I 2024-08-31 18:51:08,220] Trial 45 finished with value: 0.9901762783751398 and parameters: {'learning_rate': 0.09867093612344868, 'num_leaves': 97, 'max_depth': 42, 'min_child_samples': 12, 'subsample': 0.51868159204108, 'colsample_bytree': 0.6144412990803183, 'lambda_l1': 0.019497894659672388, 'lambda_l2': 1.045254465384934}. Best is trial 44 with value: 0.9902532768463993.\n","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Info] Number of positive: 1364404, number of negative: 1129152\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.148427 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 932\n[LightGBM] [Info] Number of data points in the train set: 2493556, number of used features: 16\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.547172 -> initscore=0.189251\n[LightGBM] [Info] Start training from score 0.189251\n","output_type":"stream"},{"name":"stderr","text":"[I 2024-08-31 18:51:46,210] Trial 46 finished with value: 0.9889459069698053 and parameters: {'learning_rate': 0.052198523787881784, 'num_leaves': 100, 'max_depth': 37, 'min_child_samples': 13, 'subsample': 0.5225610296669706, 'colsample_bytree': 0.5477096892898906, 'lambda_l1': 0.016438059887783345, 'lambda_l2': 0.12727494401255068}. Best is trial 44 with value: 0.9902532768463993.\n","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Info] Number of positive: 1364404, number of negative: 1129152\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.625629 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 932\n[LightGBM] [Info] Number of data points in the train set: 2493556, number of used features: 16\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.547172 -> initscore=0.189251\n[LightGBM] [Info] Start training from score 0.189251\n","output_type":"stream"},{"name":"stderr","text":"[I 2024-08-31 18:52:27,640] Trial 47 finished with value: 0.9898554514115584 and parameters: {'learning_rate': 0.08185932601160435, 'num_leaves': 97, 'max_depth': 43, 'min_child_samples': 12, 'subsample': 0.5009391587280277, 'colsample_bytree': 0.6121061520794631, 'lambda_l1': 0.004746642960276041, 'lambda_l2': 0.8812108640715512}. Best is trial 44 with value: 0.9902532768463993.\n","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Info] Number of positive: 1364404, number of negative: 1129152\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.146566 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 932\n[LightGBM] [Info] Number of data points in the train set: 2493556, number of used features: 16\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.547172 -> initscore=0.189251\n[LightGBM] [Info] Start training from score 0.189251\n","output_type":"stream"},{"name":"stderr","text":"[I 2024-08-31 18:53:03,491] Trial 48 finished with value: 0.9882737744811025 and parameters: {'learning_rate': 0.054684123916824715, 'num_leaves': 78, 'max_depth': 34, 'min_child_samples': 12, 'subsample': 0.5245975741457309, 'colsample_bytree': 0.5860491278716601, 'lambda_l1': 0.0056136872742402295, 'lambda_l2': 1.6136596361568885}. Best is trial 44 with value: 0.9902532768463993.\n","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Info] Number of positive: 1364404, number of negative: 1129152\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.429167 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 932\n[LightGBM] [Info] Number of data points in the train set: 2493556, number of used features: 16\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.547172 -> initscore=0.189251\n[LightGBM] [Info] Start training from score 0.189251\n","output_type":"stream"},{"name":"stderr","text":"[I 2024-08-31 18:53:43,410] Trial 49 finished with value: 0.9902981926213007 and parameters: {'learning_rate': 0.09784293277568029, 'num_leaves': 97, 'max_depth': 41, 'min_child_samples': 10, 'subsample': 0.5221943918405507, 'colsample_bytree': 0.6142566706941057, 'lambda_l1': 0.023032168440835374, 'lambda_l2': 0.628284093322658}. Best is trial 49 with value: 0.9902981926213007.\n","output_type":"stream"},{"name":"stdout","text":"Best Parameters: {'learning_rate': 0.09784293277568029, 'num_leaves': 97, 'max_depth': 41, 'min_child_samples': 10, 'subsample': 0.5221943918405507, 'colsample_bytree': 0.6142566706941057, 'lambda_l1': 0.023032168440835374, 'lambda_l2': 0.628284093322658}\n","output_type":"stream"}]},{"cell_type":"code","source":"# Print the best parameters\nbest_params = study.best_params\nprint(\"Best Parameters:\", best_params)\n\n# Train the final model with the best parameters\nfinal_params = {\n    'objective': 'binary',\n    'metric': 'binary_logloss',\n    'boosting_type': 'gbdt',\n    **best_params,\n    'seed': 42\n}\n\nfinal_model = lgb.train(final_params, lgb.Dataset(X_train, label=y_train), valid_sets=[lgb.Dataset(X_test, label=y_test)])\n\n# Evaluate the final model\ny_pred = final_model.predict(X_test, num_iteration=final_model.best_iteration)\ny_pred_binary = (y_pred > 0.5).astype(int)\n\nmcc = matthews_corrcoef(y_test, y_pred_binary)\nprint(\"Matthews Correlation Coefficient (MCC):\", mcc)\nprint(\"Accuracy:\", accuracy_score(y_test, y_pred_binary))\nprint(\"Classification Report:\\n\", classification_report(y_test, y_pred_binary))","metadata":{"execution":{"iopub.status.busy":"2024-08-31T18:53:43.424237Z","iopub.execute_input":"2024-08-31T18:53:43.424535Z","iopub.status.idle":"2024-08-31T18:54:25.021861Z","shell.execute_reply.started":"2024-08-31T18:53:43.424508Z","shell.execute_reply":"2024-08-31T18:54:25.020717Z"},"trusted":true},"execution_count":39,"outputs":[{"name":"stdout","text":"Best Parameters: {'learning_rate': 0.09784293277568029, 'num_leaves': 97, 'max_depth': 41, 'min_child_samples': 10, 'subsample': 0.5221943918405507, 'colsample_bytree': 0.6142566706941057, 'lambda_l1': 0.023032168440835374, 'lambda_l2': 0.628284093322658}\n[LightGBM] [Info] Number of positive: 1364404, number of negative: 1129152\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.421869 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 932\n[LightGBM] [Info] Number of data points in the train set: 2493556, number of used features: 16\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.547172 -> initscore=0.189251\n[LightGBM] [Info] Start training from score 0.189251\nMatthews Correlation Coefficient (MCC): 0.9804293167869135\nAccuracy: 0.9902981926213007\nClassification Report:\n               precision    recall  f1-score   support\n\n           0       0.99      0.99      0.99    282397\n           1       0.99      0.99      0.99    340992\n\n    accuracy                           0.99    623389\n   macro avg       0.99      0.99      0.99    623389\nweighted avg       0.99      0.99      0.99    623389\n\n","output_type":"stream"}]},{"cell_type":"code","source":"new_columns = {'class': 'class','cap-diameter':'cap_diameter','cap-shape':'cap_shape','cap-surface':'cap_surface',\n             'cap-color':'cap_color','does-bruise-or-bleed':'does_bruise_or_bleed','gill-attachment':'gill_attachment',\n            'gill-spacing':'gill_spacing','gill-color':'gill_color','stem-height':'stem_height','stem-width':'stem_width',\n            'stem-root':'stem_root','stem-surface':'stem_surface','stem-color':'stem_color','veil-type':'veil_type',\n            'veil-color':'veil_color','has-ring':'has_ring','ring-type':'ring_type','spore-print-color':'spore_print_color',\n            'habitat':'habitat','season':'season'}\ndf_test.rename(columns = new_columns, inplace = True)","metadata":{"execution":{"iopub.status.busy":"2024-08-31T18:54:25.023349Z","iopub.execute_input":"2024-08-31T18:54:25.023787Z","iopub.status.idle":"2024-08-31T18:54:25.032574Z","shell.execute_reply.started":"2024-08-31T18:54:25.023749Z","shell.execute_reply":"2024-08-31T18:54:25.031347Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"ids= df_test['id']","metadata":{"execution":{"iopub.status.busy":"2024-08-31T18:54:25.034333Z","iopub.execute_input":"2024-08-31T18:54:25.035049Z","iopub.status.idle":"2024-08-31T18:54:25.045245Z","shell.execute_reply.started":"2024-08-31T18:54:25.035008Z","shell.execute_reply":"2024-08-31T18:54:25.044167Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"# 2. Handle Missing Values\n# Separate numerical and categorical columns\nnumerical_cols = df_test.select_dtypes(include=['float64', 'int64']).columns\ncategorical_cols = df_test.select_dtypes(include=['object']).columns","metadata":{"execution":{"iopub.status.busy":"2024-08-31T18:54:25.046718Z","iopub.execute_input":"2024-08-31T18:54:25.047140Z","iopub.status.idle":"2024-08-31T18:54:25.520391Z","shell.execute_reply.started":"2024-08-31T18:54:25.047103Z","shell.execute_reply":"2024-08-31T18:54:25.519208Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"# For numerical columns, use the mean or median\ndf_test[numerical_cols] = numeric_imputer.fit_transform(df_test[numerical_cols])\n\n# For categorical columns, use the most frequent value\ndf_test[categorical_cols] = categorical_imputer.fit_transform(df_test[categorical_cols])\n","metadata":{"execution":{"iopub.status.busy":"2024-08-31T18:57:56.111993Z","iopub.execute_input":"2024-08-31T18:57:56.112442Z","iopub.status.idle":"2024-08-31T18:58:05.253357Z","shell.execute_reply.started":"2024-08-31T18:57:56.112408Z","shell.execute_reply":"2024-08-31T18:58:05.252358Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"code","source":"# 3. Encode Categorical Variables\n# Using LabelEncoder for simplicity\nlabel_encoders = {}\nfor col in categorical_cols:\n    le = LabelEncoder()\n    df_test[col] = le.fit_transform(df_test[col])\n    label_encoders[col] = le  # Storing the encoders for potential inverse transform\n","metadata":{"execution":{"iopub.status.busy":"2024-08-31T18:58:18.839087Z","iopub.execute_input":"2024-08-31T18:58:18.839516Z","iopub.status.idle":"2024-08-31T18:58:28.248986Z","shell.execute_reply.started":"2024-08-31T18:58:18.839484Z","shell.execute_reply":"2024-08-31T18:58:28.247912Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"code","source":"df_test.drop(['id','veil_type','spore_print_color','stem_root','veil_color'], axis =1, inplace = True)","metadata":{"execution":{"iopub.status.busy":"2024-08-31T18:58:34.307136Z","iopub.execute_input":"2024-08-31T18:58:34.307594Z","iopub.status.idle":"2024-08-31T18:58:34.462955Z","shell.execute_reply.started":"2024-08-31T18:58:34.307562Z","shell.execute_reply":"2024-08-31T18:58:34.461633Z"},"trusted":true},"execution_count":48,"outputs":[]},{"cell_type":"code","source":"predictions= final_model.predict(df_test)","metadata":{"execution":{"iopub.status.busy":"2024-08-31T18:58:46.130752Z","iopub.execute_input":"2024-08-31T18:58:46.131148Z","iopub.status.idle":"2024-08-31T18:58:53.012000Z","shell.execute_reply.started":"2024-08-31T18:58:46.131118Z","shell.execute_reply":"2024-08-31T18:58:53.010764Z"},"trusted":true},"execution_count":49,"outputs":[]},{"cell_type":"code","source":"import numpy as np\n\n# Convert probabilities to class labels (0 or 1)\nclass_labels = (predictions > 0.5).astype(int)\n\n# Map the integer labels to the original class labels ('e' and 'p')\nclass_labels = np.where(class_labels == 0, 'e', 'p')\n\n# Create a DataFrame to hold the results\nresults_df = pd.DataFrame({\n    'id': ids,\n    'class': class_labels\n})\n\n# Display the first few rows of the results\nresults_df.head()\n","metadata":{"execution":{"iopub.status.busy":"2024-08-31T18:58:59.896656Z","iopub.execute_input":"2024-08-31T18:58:59.897067Z","iopub.status.idle":"2024-08-31T18:59:00.019236Z","shell.execute_reply.started":"2024-08-31T18:58:59.897038Z","shell.execute_reply":"2024-08-31T18:59:00.018172Z"},"trusted":true},"execution_count":50,"outputs":[{"execution_count":50,"output_type":"execute_result","data":{"text/plain":"        id class\n0  3116945     p\n1  3116946     p\n2  3116947     p\n3  3116948     p\n4  3116949     e","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>class</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>3116945</td>\n      <td>p</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>3116946</td>\n      <td>p</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3116947</td>\n      <td>p</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3116948</td>\n      <td>p</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>3116949</td>\n      <td>e</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"results_df.to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2024-08-31T19:02:57.677254Z","iopub.execute_input":"2024-08-31T19:02:57.677743Z","iopub.status.idle":"2024-08-31T19:03:00.536424Z","shell.execute_reply.started":"2024-08-31T19:02:57.677709Z","shell.execute_reply":"2024-08-31T19:03:00.535176Z"},"trusted":true},"execution_count":56,"outputs":[]},{"cell_type":"code","source":"\n# Merge results with sample_submission to compare\nmerged_df = results_df.merge(df_sub, on='id', suffixes=('_pred', '_true'))\n\n# Calculate accuracy\naccuracy = np.mean(merged_df['class_pred'] == merged_df['class_true'])\n\n# Display the accuracy\nprint(f\"Accuracy: {accuracy:.2%}\")\n\n# Display the first few rows of the results\nmerged_df.head()","metadata":{"execution":{"iopub.status.busy":"2024-08-31T18:59:36.409181Z","iopub.execute_input":"2024-08-31T18:59:36.409607Z","iopub.status.idle":"2024-08-31T18:59:37.042479Z","shell.execute_reply.started":"2024-08-31T18:59:36.409575Z","shell.execute_reply":"2024-08-31T18:59:37.041343Z"},"trusted":true},"execution_count":52,"outputs":[{"name":"stdout","text":"Accuracy: 39.99%\n","output_type":"stream"},{"execution_count":52,"output_type":"execute_result","data":{"text/plain":"        id class_pred class_true\n0  3116945          p          e\n1  3116946          p          e\n2  3116947          p          e\n3  3116948          p          e\n4  3116949          e          e","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>class_pred</th>\n      <th>class_true</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>3116945</td>\n      <td>p</td>\n      <td>e</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>3116946</td>\n      <td>p</td>\n      <td>e</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3116947</td>\n      <td>p</td>\n      <td>e</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3116948</td>\n      <td>p</td>\n      <td>e</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>3116949</td>\n      <td>e</td>\n      <td>e</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# Verify the class distribution in the sample_submission\nclass_distribution = df_sub['class'].value_counts()\nprint(class_distribution)\n\n# Plot the distribution\nsns.countplot(x='class', data=df_sub)\nplt.title('Class Distribution in Sample Submission')\nplt.show()\n\n# Check model predictions\npredicted_class_distribution = results_df['class'].value_counts()\nprint(predicted_class_distribution)\n\n# Plot the distribution of model predictions\nsns.countplot(x='class', data=results_df)\nplt.title('Predicted Class Distribution')\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2024-08-31T19:00:21.866503Z","iopub.execute_input":"2024-08-31T19:00:21.866961Z","iopub.status.idle":"2024-08-31T19:00:27.174692Z","shell.execute_reply.started":"2024-08-31T19:00:21.866926Z","shell.execute_reply":"2024-08-31T19:00:27.173189Z"},"trusted":true},"execution_count":54,"outputs":[{"name":"stdout","text":"class\ne    2077964\nName: count, dtype: int64\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 1 Axes>","image/png":"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"},"metadata":{}},{"name":"stdout","text":"class\np    1246942\ne     831022\nName: count, dtype: int64\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 1 Axes>","image/png":"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"},"metadata":{}}]},{"cell_type":"code","source":"# Calculate MCC\nmcc = matthews_corrcoef(merged_df['class_true'], merged_df['class_pred'])\n\n# Display the MCC\nprint(f\"Matthews Correlation Coefficient: {mcc:.4f}\")","metadata":{"execution":{"iopub.status.busy":"2024-08-31T19:00:41.127013Z","iopub.execute_input":"2024-08-31T19:00:41.128292Z","iopub.status.idle":"2024-08-31T19:00:53.795649Z","shell.execute_reply.started":"2024-08-31T19:00:41.128248Z","shell.execute_reply":"2024-08-31T19:00:53.794489Z"},"trusted":true},"execution_count":55,"outputs":[{"name":"stdout","text":"Matthews Correlation Coefficient: 0.0000\n","output_type":"stream"}]}]}